{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d0b92635-6aae-49ee-90c3-9c7038633219",
      "metadata": {
        "id": "d0b92635-6aae-49ee-90c3-9c7038633219"
      },
      "source": [
        "# LLM Prompt Engineering Lab\n",
        "## Tree of Thought Prompting with GPT4o-mini"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fc0500-2447-487b-b720-a15ac5897055",
      "metadata": {
        "id": "84fc0500-2447-487b-b720-a15ac5897055"
      },
      "source": [
        "Preliminaries: import libraries, read in the OpenAI API key and pass it to an OpenAI object constructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa497f1d-b384-4917-80e3-1be73ccc141f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa497f1d-b384-4917-80e3-1be73ccc141f",
        "outputId": "e65b20fe-f750-4172-90fa-a2548beac3ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anytree in /usr/local/lib/python3.12/dist-packages (2.13.0)\n"
          ]
        }
      ],
      "source": [
        "# Import libraries, set API key\n",
        "!pip install anytree\n",
        "from anytree import Node, RenderTree\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/sample_data')\n",
        "import ASCIImaze\n",
        "import os\n",
        "import re\n",
        "\n",
        "# This chunk of code reads an OpenAI API key from a chosen environment variable, which must be predefined.\n",
        "# For my own dev, I'm using my personal API key. This will not be provided to others, you must use one you have\n",
        "# access to.\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=\"Insert key here\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d7938f-6077-4510-872a-c92e08af316d",
      "metadata": {
        "id": "c0d7938f-6077-4510-872a-c92e08af316d"
      },
      "source": [
        "<b>First prompt:</b> Recognize the ASCII maze, and format it as a single-line string, with the different lines of the maze delimited by \"|\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "bad019ab-61ba-4c24-8c02-089543775ac7",
      "metadata": {
        "id": "bad019ab-61ba-4c24-8c02-089543775ac7"
      },
      "outputs": [],
      "source": [
        "extract_maze_system_prompt = \" Recognize the ASCII maze, and format it as a single-line string, with the different lines of the maze delimited by '|'. Return nothing but the string representing the maze.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92c929a-1cab-4f46-9c43-05c089d0bd15",
      "metadata": {
        "id": "a92c929a-1cab-4f46-9c43-05c089d0bd15"
      },
      "source": [
        "<b>Second prompt:</b> Format the 3x3 neighborhood in the same manner as the ASCII maze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "0fd249fd-3ef4-429c-957e-661850c430d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0fd249fd-3ef4-429c-957e-661850c430d3",
        "outputId": "4797fef8-0f76-4da1-d61a-c67e0bd0dd81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:6: SyntaxWarning: invalid escape sequence '\\|'\n",
            "<>:6: SyntaxWarning: invalid escape sequence '\\|'\n",
            "/tmp/ipython-input-1658719250.py:6: SyntaxWarning: invalid escape sequence '\\|'\n",
            "  The output MUST follow this regex: ^.{3}\\|.{3}\\|.{3}$. Make sure to retain spaces.\n"
          ]
        }
      ],
      "source": [
        "generate_thought_context_system_prompt = \"\"\"\n",
        "You are analyzing a 3x3 neighborhood of the maze.\n",
        "Convert it into a single-line string where each row is separated by the character '|'.\n",
        "Return only the single-line string, with no extra text or formatting. 11 characters total including the delimiter\n",
        "\n",
        "The output MUST follow this regex: ^.{3}\\|.{3}\\|.{3}$. Make sure to retain spaces.\n",
        "\n",
        "Examples (showing correct format):\n",
        "\n",
        "Input:\n",
        "###\n",
        " *\n",
        " #\n",
        "\n",
        "Output:\n",
        "###| * | #\n",
        "\n",
        "Input:\n",
        "# #\n",
        "#*#\n",
        "#E#\n",
        "\n",
        "Output:\n",
        "# #|#*#|#E#\n",
        "\n",
        "Input:\n",
        "#S#\n",
        "#*\n",
        "# #\n",
        "\n",
        "Output:\n",
        "#S#|#* |# #\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0fd444-f009-480e-95d9-34db92315061",
      "metadata": {
        "id": "da0fd444-f009-480e-95d9-34db92315061"
      },
      "source": [
        "<b>Third prompt:</b> Based on the refomatted ASCII maze and neighborhood from prompts 1 and 2 above, choose the next move to make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9dd8cfb0-8ee2-4cd7-8bec-593db7cc638b",
      "metadata": {
        "id": "9dd8cfb0-8ee2-4cd7-8bec-593db7cc638b"
      },
      "outputs": [],
      "source": [
        "\n",
        "generate_thought_system_prompt = \"\"\"\n",
        "You are a maze navigation agent making a single move at a time.\n",
        "You must choose exactly one move from the list of valid options.\n",
        "Never invent or imagine directions that are not in the list.\n",
        "Never describe or explain your reasoning.\n",
        "Only output one capital letter on a single line, with no punctuation or commentary.\n",
        "\n",
        "Valid moves: {vmove}\n",
        "\n",
        "Your entire output must be exactly one of these characters — nothing else.\n",
        "Example:\n",
        "If valid moves are \"L, D\", valid output: D\n",
        "If valid moves are \"R\", valid output: R\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TUCWUE6rPH8-",
      "metadata": {
        "id": "TUCWUE6rPH8-"
      },
      "source": [
        "Output rule: reply with **one uppercase letter** (U/D/L/R) only — no words, punctuation, or reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okKg6qSRPGAX",
      "metadata": {
        "id": "okKg6qSRPGAX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a98f5d0f-4970-45ad-9cd6-387d8abac60a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a98f5d0f-4970-45ad-9cd6-387d8abac60a",
        "outputId": "cefd62a4-175b-4dc5-df12-d35b939cee74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:240: SyntaxWarning: invalid escape sequence '\\&'\n",
            "<>:240: SyntaxWarning: invalid escape sequence '\\&'\n",
            "/tmp/ipython-input-2598231178.py:240: SyntaxWarning: invalid escape sequence '\\&'\n",
            "  LLM_move_temp = re.sub('\\&\\&\\&.+\\&\\&\\&', '', LLM_move.content, flags=re.DOTALL)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['maze_map1', 'maze_map2', 'maze_map3'])\n",
            "output:  You have your starting position 'S', the end position 'E' and your current position will be indicated after every move with '*'.\n",
            "    Walls are labeled as '#' and are impenetrable. This is done one turn at a time giving me the direction you would like to go\n",
            "    (up 'U', down 'D', left 'L', right 'R'). You can also request a 3x3 grid of the immediate area around you with '3'.\n",
            "#######\n",
            "#S    #\n",
            "# # # #\n",
            "# # #E#\n",
            "#######\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "``` You have your starting position 'S', the end position 'E' and your current position will be indicated after every move with '*'.\n",
            "    Walls are labeled as '#' and are impenetrable. This is done one turn at a time giving me the direction you would like to go\n",
            "    (up 'U', down 'D', left 'L', right 'R'). You can also request a 3x3 grid of the immediate area around you with '3'.\n",
            "#######\n",
            "#S    #\n",
            "# # # #\n",
            "# # #E#\n",
            "#######\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): ```\n",
            "maze_single_line `#######|#S    #|# # # #|# # #E#|#######`\n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "###\n",
            "#* \n",
            "# #\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied ###|#* |# #\n",
            "Valid moves are ['R', 'D']\n",
            "I choose move R\n",
            "This is move 1\n",
            " \n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "###\n",
            "S* \n",
            " # \n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied ###|S* | # \n",
            "Valid moves are ['R']\n",
            "I choose move R\n",
            "This is move 2\n",
            " \n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "###\n",
            " * \n",
            "# #\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied ###| * |# #\n",
            "Valid moves are ['R', 'D']\n",
            "I choose move R\n",
            "This is move 3\n",
            " \n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "###\n",
            " * \n",
            " # \n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied ###| * | # \n",
            "Valid moves are ['R']\n",
            "I choose move R\n",
            "This is move 4\n",
            " \n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "###\n",
            " *#\n",
            "# #\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied ###| *#|# #\n",
            "Valid moves are ['D']\n",
            "I choose move D\n",
            "This is move 5\n",
            " \n",
            "Output reads: Here is a 3x3 of your current position:\n",
            "  #\n",
            "#*#\n",
            "#E#\n",
            "Enter a move direction (U, D, L, R, or 3 (for a 3x3 of the current position)): \n",
            "evaluate thought recevied   #|#*#|#E#\n",
            "Valid moves are ['D']\n",
            "I choose move D\n",
            "This is move 6\n",
            " \n",
            "I finished\n",
            "\n",
            "Total input (prompt) tokens used: 2327\n",
            "Total output (completion) tokens used: 72\n",
            "Total tokens processed: 2399\n"
          ]
        }
      ],
      "source": [
        "# Possible models:\n",
        "# gpt-3.5-turbo\n",
        "# gpt-4o-mini\n",
        "total_input_tokens = 0\n",
        "total_output_tokens = 0\n",
        "# get_completion is a helper method suggested in the DeepLearning.ai course on prompt engineering.\n",
        "# I modified this version to use the OpenAI 1.0 implementation. The \"client\" object was passed an API key in line 24\n",
        "def get_completion(system_prompt, user_prompt, my_model=\"gpt-4o-mini\"):\n",
        "    global total_input_tokens, total_output_tokens\n",
        "    completion = client.chat.completions.create(\n",
        "        model=my_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\",\n",
        "             \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "    usage = completion.usage\n",
        "    total_input_tokens += usage.prompt_tokens\n",
        "    total_output_tokens += usage.completion_tokens\n",
        "\n",
        "\n",
        "    return completion.choices[0].message\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Utility function for displaying trees. Core code from the anytree package documentation.\n",
        "def render_that_tree(mytree):\n",
        "    for pre, _, node in RenderTree(mytree):\n",
        "        print(\"%s%s\" % (pre, node.name))\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Backtracking subroutine for Tree of Thought. Updates teh parent's state info to prune the dead-end branch we are\n",
        "#  backtracking from (by setting that position in the stored 3x3 to '#').\n",
        "\n",
        "def tree_backtrack(deadend_node, curr_move):\n",
        "\n",
        "    curr_node = deadend_node.parent\n",
        "\n",
        "    if deadend_node.move == 'D':\n",
        "        temp = list(curr_node.name)\n",
        "        temp[9] = '#'\n",
        "        curr_node.name = ''.join(temp)\n",
        "\n",
        "    elif deadend_node.move == 'U':\n",
        "        temp = list(curr_node.name)\n",
        "        temp[1] = '#'\n",
        "        curr_node.name = ''.join(temp)\n",
        "\n",
        "    elif deadend_node.move == 'L':\n",
        "        temp = list(curr_node.name)\n",
        "        temp[4] = '#'\n",
        "        curr_node.name = ''.join(temp)\n",
        "\n",
        "    elif deadend_node.move == 'R':\n",
        "        temp = list(curr_node.name)\n",
        "        temp[6] = '#'\n",
        "        curr_node.name = ''.join(temp)\n",
        "\n",
        "    else:\n",
        "        print(\"Illegal move in backtracking\")\n",
        "        return None\n",
        "\n",
        "    return curr_node\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Add node subroutine for Tree of Thought. Pretty short, but putting it here makes teh main loop cleaner.\n",
        "#  This also pushes the tree updates out to subroutines, which is common and familiar. Leaves just teh LLM and game\n",
        "#  logic in the main loop, which I think is good.\n",
        "def add_node(curr_node, LLM_move_cleaned):\n",
        "    # New node is a child of the current node. State has to be determined on next iteration. The move to reach this\n",
        "    #  node from its parent is recorded as the \"move\" attribute. The move to reach its parent from this node\n",
        "    #  is recorded as the \"backtrack\" attribute.\n",
        "\n",
        "    # Have to determine the backtrack attribute by reversing LLM_cleaned_move. Another elif tree here.\n",
        "    if LLM_move_cleaned.find('D') >= 0:\n",
        "        rev = 'U'\n",
        "\n",
        "    elif LLM_move_cleaned.find('U') >= 0:\n",
        "        rev = 'D'\n",
        "\n",
        "    elif LLM_move_cleaned.find('L') >= 0:\n",
        "        rev = 'R'\n",
        "\n",
        "    elif LLM_move_cleaned.find('R') >= 0:\n",
        "        rev = 'L'\n",
        "\n",
        "    else:\n",
        "        print(\"Not a legal move\")\n",
        "        return None\n",
        "\n",
        "    temp = Node(parent=curr_node, name=\"\", move=LLM_move_cleaned, backtrack=rev)\n",
        "\n",
        "    return temp\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "def evaluate_thought(curr_local, curr_node):\n",
        "    # Pre: curr_local is the 3x3 neighborhood for the current location in the maze.\n",
        "    # Format ###|#*#|###\n",
        "    # curr_node is the current node of the tree, the center point of the 3x3 local neighborhood.\n",
        "    # Post: none\n",
        "    # Returns: List of valid moves, each a 1-character string from {U, D, L, R}\n",
        "\n",
        "    # Create output list, convert input string to a list.\n",
        "\n",
        "    # Debug\n",
        "    print(f\"evaluate thought recevied {curr_local}\")\n",
        "    # Debug\n",
        "\n",
        "    valid_moves = []\n",
        "    maze_neigh = curr_local\n",
        "    # Checking validity of each possible move\n",
        "    if maze_neigh[1] in [' ', 'S', 'E']:\n",
        "        valid_moves.append('U')\n",
        "    if maze_neigh[4] in [' ', 'S', 'E']:\n",
        "        valid_moves.append('L')\n",
        "    if maze_neigh[6] in [' ', 'S', 'E']:\n",
        "        valid_moves.append('R')\n",
        "    if maze_neigh[9] in [' ', 'S', 'E']:\n",
        "        valid_moves.append('D')\n",
        "\n",
        "    # If there’s more than one open move, drop the backtrack one.\n",
        "    if len(valid_moves) > 1 and curr_node.backtrack in valid_moves:\n",
        "        valid_moves.remove(curr_node.backtrack)\n",
        "\n",
        "    # If no moves left, the only option is to backtrack.\n",
        "    if not valid_moves:\n",
        "        valid_moves.append(curr_node.backtrack)\n",
        "\n",
        "    return valid_moves\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Guards for 1st iteration, context request.\n",
        "ready_for_input = False\n",
        "need_context_update = True\n",
        "mazeTreeStart = Node(name=\"\", move=\"\", backtrack=\"\")\n",
        "curr_node = mazeTreeStart\n",
        "# Debug\n",
        "counter = 0\n",
        "\n",
        "print(ASCIImaze.Maze.maps.keys())\n",
        "# The maze game loop is contained in the maze.solve() method. Call the constructor, and then enter a for loop\n",
        "#  to receive outputs from maze.solve(), and respond with our inputs.\n",
        "maze = ASCIImaze.Maze(\"maze_map3\", show_moves=False, show_coords=False)\n",
        "for output in maze.solve():\n",
        "    if (not ready_for_input):\n",
        "        # On the first iteration, we get the maze to solve. Bring it into the LLM, then goto next iteration; that\n",
        "        #  will be the first opportunity to pass an input to the ASCIImaze solver.\n",
        "        print(\"output:\", output)\n",
        "        # Going to pull the maze into the LLM's chat history now.\n",
        "        user_prompt=f\"\"\"```{output}```\"\"\"\n",
        "        print(user_prompt)\n",
        "        maze_to_solve = get_completion(extract_maze_system_prompt, user_prompt)\n",
        "        print('maze_single_line',maze_to_solve.content)\n",
        "        ready_for_input = True\n",
        "        continue\n",
        "\n",
        "    if (need_context_update):\n",
        "        # Grab context by passing '3' to ASCIIMaze. Isolated so can use stored context instead.\n",
        "        # Must go to next iteration b/c only then will 'output' be updated with the 3x3 neighborhood.\n",
        "        maze.get_user_move('3')\n",
        "        need_context_update = False\n",
        "        continue\n",
        "\n",
        "    if \"Maze solved!\" in output:\n",
        "        # Victory!\n",
        "        print(output)\n",
        "        break\n",
        "\n",
        "\n",
        "    # Pull in the current 3x3 neighborhood, IF the current node does not already have a state. Otherwise, this is a\n",
        "    #  backtracking situation.\n",
        "\n",
        "    # Debug\n",
        "    print(f\"Output reads: {output}\")\n",
        "    if curr_node.name == \"\":\n",
        "        # Case for a node not previously visited.\n",
        "        user_prompt = f\"```{output}```\"\n",
        "        neigh = get_completion(generate_thought_context_system_prompt, user_prompt)\n",
        "        curr_node.name = neigh.content\n",
        "\n",
        "        # print(\"Neighborhood:\")\n",
        "        # print(\"\\n\".join(curr_node.name.split(\"|\")))\n",
        "\n",
        "\n",
        "    # Evaluate the current position; this is actually evaluating the through generated in the previous round.\n",
        "    # Possible results are {{valid moves}, <just the backtrack direction>}\n",
        "    # Backtrack if so indicated, generate a new thought if there are other valid moves.\n",
        "    # The ASCIImaze.maze.solve() method, the main game loop, outputs a message when you correctly solve the maze, you\n",
        "    #  don't need to figure out if the LLM has won the game. Just check for the victory message. Done above.\n",
        "\n",
        "\n",
        "\n",
        "    valid_moves_cleaned = evaluate_thought(curr_node.name, curr_node)\n",
        "    print(f\"Valid moves are {valid_moves_cleaned}\")\n",
        "\n",
        "\n",
        "\n",
        "    if len(valid_moves_cleaned) == 1 and valid_moves_cleaned[0] == curr_node.backtrack:\n",
        "        # The only move detected is the backtrack direction, so follow it, both in the maze and the tree.\n",
        "        maze.get_user_move(curr_node.backtrack)\n",
        "        curr_node = tree_backtrack(curr_node, curr_node.backtrack)\n",
        "\n",
        "        # Do not update context, the state in curr_node has already been updated. BUT this blows up an assumption :(\n",
        "        need_context_update = False\n",
        "\n",
        "        # The valid moves from the last eval step are no longer correct. Go to the next iteration, get a new move set.\n",
        "        continue\n",
        "\n",
        "    # Generate a thought\n",
        "    # The LLM chooses a next move, which will be a child of the current node\n",
        "    # Again, inner monologues are used to recreate the 2D mazes.\n",
        "    user_prompt = f\"\"\"```{maze_to_solve.content}, {curr_node.name}```\"\"\"\n",
        "\n",
        "    # Adding the backtrack move to thought generation. Remember to deal with root node (no parent).\n",
        "    valid_moves_temp = \", \".join(valid_moves_cleaned)\n",
        "\n",
        "    # Initial value for LLM_move, for loop entry\n",
        "    LLM_move_cleaned = ['Z']\n",
        "\n",
        "    # Loop to check for valid move.\n",
        "    # LLM_move_cleaned should be a single-element list. If that element is not part of the valid move set, try again.\n",
        "    while valid_moves_temp.find(LLM_move_cleaned[0]) < 0:\n",
        "\n",
        "        #print(f\"Moves going to LLM are {valid_moves_temp}\")\n",
        "\n",
        "        if curr_node.parent != None:\n",
        "            LLM_move = get_completion(generate_thought_system_prompt.format(vmove=valid_moves_temp,\n",
        "                                                                    backmove=curr_node.backtrack), user_prompt)\n",
        "        else:\n",
        "            LLM_move = get_completion(generate_thought_system_prompt.format(vmove=valid_moves_temp,\n",
        "                                                      ackmove=None), user_prompt)\n",
        "        LLM_move_temp = re.sub('\\&\\&\\&.+\\&\\&\\&', '', LLM_move.content, flags=re.DOTALL)\n",
        "        # Again, another regex needed.\n",
        "        LLM_move_cleaned = re.findall(\"[A-Z]\", LLM_move_temp)\n",
        "        print(f\"I choose move {LLM_move_cleaned[0]}\")\n",
        "    # Error check\n",
        "    if len(LLM_move_cleaned) > 1:\n",
        "        print(\"Extra stuff in the generated thought, aborting\")\n",
        "        break\n",
        "\n",
        "\n",
        "    # Make the chosen move, and add the corresponding node to the tree.\n",
        "    maze.get_user_move(LLM_move_cleaned[0])\n",
        "    curr_node = add_node(curr_node, LLM_move_cleaned[0])\n",
        "    if curr_node is None:\n",
        "        print(\"You goofed.\")\n",
        "        print(LLM_move_cleaned)\n",
        "    # Debug\n",
        "    counter = counter + 1\n",
        "    #print(f\"I choose move {LLM_move_cleaned}\")\n",
        "    print(f\"This is move {counter}\")\n",
        "    print(\" \")\n",
        "\n",
        "    # Need the next 3x3 neighborhood.\n",
        "    need_context_update = True\n",
        "\n",
        "print(\"I finished\")\n",
        "print(f\"\\nTotal input (prompt) tokens used: {total_input_tokens}\")\n",
        "print(f\"Total output (completion) tokens used: {total_output_tokens}\")\n",
        "print(f\"Total tokens processed: {total_input_tokens + total_output_tokens}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "an_BKh6Bo_T7",
      "metadata": {
        "id": "an_BKh6Bo_T7"
      },
      "source": [
        "# Report\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this lab we used prompt engineering strategies to accompany a Tree-of-Thought prompting strategy to guide an LLM (GPT-4o-mini) to solve an ASCII-based maze game. The goal was to design a series of prompts that:\n",
        "\n",
        "\n",
        "*   Flatten an NxM maze into a 1D string where rows were delimited with '|'.\n",
        "*   Similarly flatten a 3x3 grid representing the immediate surroundings of the current state.\n",
        "*   Choose a list from a list of valid moves.\n",
        "\n",
        "To do this, minimal code changes were made, but the three prompts had to be designed to guide the LLM's decision making. A Troo-of-Thought strategy was employed for this assignment.\n",
        "\n",
        "## Tree-of-Thought Prompting\n",
        "\n",
        "Tree-of-Thought prompting is a form of reasoning that allowsa model to consider multiple options before making a decision. Instead of producing a single linear reasoning chain, Tree-of-Thougt builds a search tree where each node is a partial solution. The model evaluates branches, expands promising paths much like a human exploring possible strategies.\n",
        "In this lab, this was implemented using a sort of DFS that explored one move sequence to completion before backtracking.\n",
        "\n",
        "Based on this framework, the lab was conducted by making minimal code changes and prompting teh LLM to conduct various aspects of the maze solving process.\n",
        "\n",
        "## Results\n",
        "\n",
        "Results and tokens used for each maze are as follows:  \n",
        "\n",
        "Maze 1:\n",
        "*   Result: Success\n",
        "*   Moves required: 15\n",
        "*   Input tokens used: 5630\n",
        "*   Output tokens used: 154\n",
        "*   Total tokens used: 5784\n",
        "\n",
        "Maze 2:\n",
        "*   Result: Success\n",
        "*   Moves required: 10\n",
        "*   Input tokens used: 3893\n",
        "*   Output tokens used: 118\n",
        "*   Total tokens used: 4011\n",
        "\n",
        "Maze 3:\n",
        "*   Result: Success\n",
        "*   Moves required: 5\n",
        "*   Input tokens used: 2327\n",
        "*   Output tokens used: 72\n",
        "*   Total tokens used: 2399\n",
        "\n",
        "\n",
        "\n",
        "As you can see, the prompts were sufficient for the LLM to make decisions that lead to the solved maze. On top of that, the maze solutions that were achieve through the techniques mentioned above were actual all the most optimal solution to the mazes, although this behavior isn't guaranteed for all mazes. Also, this prompting strategy, and its associated prompts could reasonably solve any number of properly formatted ASCII mazes, which is the ultimate goal of any solution to a general problem.\n",
        "\n",
        "It might appear that that, given these results, this method of LLM prompting is a great method for maze solving purposes, but this was largely found to be untrue. Though the strategy was successful in achieving its maze solving goal, it's latency, probabilistic nature, and associated costs make it a problematic candidate for problems of this type. Communicating with a remote LLM, and the time it takes to generate a response makes this process very slow. Also, since these models aren't deterministic, the results aren't always consistent accross multiple runs, even on the same maze. Lastly, there are economic considerations that can't be ignore, and the fact that a solution costs money through it's access to the OpenAI API makes the long term and large scale growth of this kind of solution very unsustainable. Also, to achieve the corect result via prompting required significant effort through trial and error.\n",
        "\n",
        "Therefore, I would not recommend this method to solve this problem. For concrete grid mazes, prefer a conventional algorithm. Tree of Thought prompting is useful as a teaching and research tool to stabilize multi-step LLM reasoning, but it's not the right engine for the task.\n",
        "\n",
        "## Costs\n",
        "\n",
        "As shown above, the costs per solution is seen to be between 2327-5630 tokens, depending on the maze. I wasn't able to find an exact figure for the price of tokens for gpt4o-mini, but allow me to illustrate the approximate (and likely upper bound) of the price per solution through a comparable gpt5-mini. The prices for tokens are $0.250 per 1 million input and $2 per 1 million output tokens. This translates to the following cost when factoring in tokens used and the split between input and output:\n",
        "\n",
        "\n",
        "\n",
        "*   Maze 1: $0.00172\n",
        "\n",
        "*   Maze 2: $0.001212\n",
        "\n",
        "*   Maze 3: $0.000726\n",
        "\n",
        "These costs are small, but could stack overtime, hence the verdict to avoid using LLMs to solve this sort of problem.\n",
        "\n",
        "\n",
        "##LLMs and Spatial Reasoning\n",
        "\n",
        "LLMs are decent at local spatial reasoning when you lock things down: serialize the map (|-delimited), list valid actions {U,D,L,R}, forbid walls/repeats, and they’ll usually pick a sensible next step. Tree-of-Thought + DFS cuts down thrashing and keeps progress moving, but the model is still stochastic and can misread the grid, so optimal and repeatable paths aren’t guaranteed. Bottom line is to use the LLM to propose candidates under strict formatting and let a classical solver (BFS/A*) handle the actual pathfinding for speed, determinism, and cost.\n",
        "\n",
        "Modern research tends to agree with this standpoint; External benchmarks consistently show that LLMs/VLMs are shaky at true spatial reasoning without heavy scaffolding. In fact, a study analyzed 13 different models in 2025, and determined that average accuracy ≈ random on core spatial tasks, such as the maze solving task of this lab. Clearly, LLM, as the name suggests, is better for natural language applications, and is far weaker in the area of spatial resoning. These findings line up with our lab experience, LLMs can follow local rules when tightly constrained, but global layout and long-horizon planning remain brittle.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "With Tree-of-Thought and strict prompts, GPT-4o-mini solved all three mazes, but it needed tight scaffolding and still behaved stochastically. Each run cost about $0.0007–$0.0017 at our rates and added latency. For grid mazes, classical BFS/DFS/A* is faster, deterministic, and basically free. Keep the LLM for parsing state, proposing candidates, or explaining a route and probably don’t use it as the pathfinder.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Sources\n",
        "\n",
        "\n",
        "*   gpt4o-mini pricing: https://openai.com/api/pricing/\n",
        "*   spatial reasoning study: https://arxiv.org/html/2503.19707v1?utm_source=chatgpt.com\n",
        "*   ECE 449 course material\n",
        "*   ECE 449 Lab 2 Document\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffxJaqE14vFT",
      "metadata": {
        "id": "ffxJaqE14vFT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
